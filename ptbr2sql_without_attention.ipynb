{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [i for i in string.ascii_uppercase + string.ascii_lowercase + string.digits + string.punctuation + ' ' + '\\t' + '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_pos = lambda c: chars.index(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('data/dataset_random.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_ptbr = len(max(samples[1][1:], key=len))\n",
    "max_len_sql = len(max(samples[1][1:], key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbr = samples[1][1:].tolist()\n",
    "sql = samples[2][1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbr_tokenized = np.zeros((num_samples, max_len_ptbr, len(chars)))\n",
    "sql_tokenized = np.zeros((num_samples, max_len_sql, len(chars)))\n",
    "target = np.zeros((num_samples, max_len_sql, len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(samples)-1):\n",
    "    for j, ch in enumerate(ptbr[i]):\n",
    "        ptbr_tokenized[i, j, chars_pos(ch)] = 1\n",
    "    \n",
    "    for j, ch in enumerate(sql[i]):\n",
    "        sql_tokenized[i, j, chars_pos(ch)] = 1\n",
    "        \n",
    "        if j > 0:\n",
    "            target[i, j-1, chars_pos(ch)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_input = Input((None, len(chars)))\n",
    "e_lstm = LSTM(256, return_state=True)\n",
    "e_output, h, c = e_lstm(e_input)\n",
    "e_states = [h, c]\n",
    "d_input = Input((None, len(chars)))\n",
    "d_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "d_output, _, _ = d_lstm(d_input, initial_state=e_states)\n",
    "d_dense = Dense(len(chars), activation='softmax')\n",
    "d_output = d_dense(d_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[e_input, d_input], outputs=[d_output])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19200 samples, validate on 4801 samples\n",
      "Epoch 1/50\n",
      "19200/19200 [==============================] - 93s 5ms/step - loss: 1.0928 - val_loss: 1.2529\n",
      "Epoch 2/50\n",
      "19200/19200 [==============================] - 89s 5ms/step - loss: 0.9192 - val_loss: 1.2280\n",
      "Epoch 3/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.9107 - val_loss: 1.2210\n",
      "Epoch 4/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.9076 - val_loss: 1.2225\n",
      "Epoch 5/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.9016 - val_loss: 1.2144\n",
      "Epoch 6/50\n",
      "19200/19200 [==============================] - 86s 5ms/step - loss: 0.9090 - val_loss: 1.2218\n",
      "Epoch 7/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.9025 - val_loss: 1.2133\n",
      "Epoch 8/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.9000 - val_loss: 1.2133\n",
      "Epoch 9/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8994 - val_loss: 1.2123\n",
      "Epoch 10/50\n",
      "19200/19200 [==============================] - 90s 5ms/step - loss: 0.8989 - val_loss: 1.2130\n",
      "Epoch 11/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8986 - val_loss: 1.2128\n",
      "Epoch 12/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8983 - val_loss: 1.2124\n",
      "Epoch 13/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8981 - val_loss: 1.2126\n",
      "Epoch 14/50\n",
      "19200/19200 [==============================] - 86s 4ms/step - loss: 0.9030 - val_loss: 1.2167\n",
      "Epoch 15/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.9031 - val_loss: 1.2140\n",
      "Epoch 16/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8992 - val_loss: 1.2123\n",
      "Epoch 17/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8948 - val_loss: 1.2019\n",
      "Epoch 18/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8870 - val_loss: 1.1947\n",
      "Epoch 19/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8815 - val_loss: 1.1929\n",
      "Epoch 20/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8787 - val_loss: 1.1891\n",
      "Epoch 21/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8756 - val_loss: 1.1852\n",
      "Epoch 22/50\n",
      "19200/19200 [==============================] - 85s 4ms/step - loss: 0.8728 - val_loss: 1.1826\n",
      "Epoch 23/50\n",
      "19200/19200 [==============================] - 90s 5ms/step - loss: 0.8708 - val_loss: 1.1861\n",
      "Epoch 24/50\n",
      "19200/19200 [==============================] - 89s 5ms/step - loss: 0.8690 - val_loss: 1.1812\n",
      "Epoch 25/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8665 - val_loss: 1.1788\n",
      "Epoch 26/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8667 - val_loss: 1.1936\n",
      "Epoch 27/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8649 - val_loss: 1.1789\n",
      "Epoch 28/50\n",
      "19200/19200 [==============================] - 89s 5ms/step - loss: 0.8661 - val_loss: 1.1811\n",
      "Epoch 29/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8649 - val_loss: 1.1778\n",
      "Epoch 30/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8638 - val_loss: 1.1805\n",
      "Epoch 31/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8615 - val_loss: 1.1783\n",
      "Epoch 32/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8627 - val_loss: 1.1800\n",
      "Epoch 33/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8604 - val_loss: 1.1814\n",
      "Epoch 34/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8601 - val_loss: 1.1801\n",
      "Epoch 35/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8584 - val_loss: 1.1827\n",
      "Epoch 36/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8571 - val_loss: 1.1802\n",
      "Epoch 37/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8560 - val_loss: 1.1775\n",
      "Epoch 38/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8539 - val_loss: 1.1728\n",
      "Epoch 39/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8509 - val_loss: 1.1738\n",
      "Epoch 40/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8497 - val_loss: 1.1714\n",
      "Epoch 41/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8441 - val_loss: 1.1615\n",
      "Epoch 42/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8339 - val_loss: 1.1500\n",
      "Epoch 43/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8270 - val_loss: 1.1428\n",
      "Epoch 44/50\n",
      "19200/19200 [==============================] - 86s 4ms/step - loss: 0.8203 - val_loss: 1.1444\n",
      "Epoch 45/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8167 - val_loss: 1.1348\n",
      "Epoch 46/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.8101 - val_loss: 1.1290\n",
      "Epoch 47/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.8052 - val_loss: 1.1275\n",
      "Epoch 48/50\n",
      "19200/19200 [==============================] - 87s 5ms/step - loss: 0.7993 - val_loss: 1.1289\n",
      "Epoch 49/50\n",
      "19200/19200 [==============================] - 86s 4ms/step - loss: 0.7964 - val_loss: 1.1291\n",
      "Epoch 50/50\n",
      "19200/19200 [==============================] - 88s 5ms/step - loss: 0.7911 - val_loss: 1.1237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d96680940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[ptbr_tokenized, sql_tokenized], y=target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('models/ptbr2sql_without_attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_inference_model = Model(e_input, e_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_state_h = Input((256,))\n",
    "d_state_c = Input((256,))\n",
    "d_input_states = [d_state_h, d_state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_output, d_h, d_c = d_lstm(d_input, initial_state=d_input_states)\n",
    "d_states = [d_h, d_c]\n",
    "d_output = d_dense(d_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_inference_model = Model(inputs=[d_input] + d_input_states, outputs=[d_output] + d_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(s):\n",
    "    states = e_inference_model.predict(s)\n",
    "    \n",
    "    target = np.zeros((1, 1, len(chars)))\n",
    "    target[0, 0, chars_pos('\\t')] = 1\n",
    "    \n",
    "    sql = ''\n",
    "    stop = False\n",
    "    \n",
    "    while not stop:\n",
    "        d_out, d_h, d_c = d_inference_model.predict(x=[target] + states)\n",
    "        \n",
    "        max_index = np.argmax(d_out[0, -1, :])\n",
    "        sampled = chars[max_index]\n",
    "        sql += str(sampled)\n",
    "        \n",
    "        if(sampled == '\\n' or (len(sql) > max_len_sql)):\n",
    "            stop = True\n",
    "            \n",
    "        target = np.zeros((1, 1, len(chars)))\n",
    "        target[0, 0, max_index] = 1\n",
    "        \n",
    "        states = [d_h, d_c]\n",
    "    \n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela x1v3NLJGBFq1F6k\n",
      "Output: select * from DzgggQ3GQlhhcZ\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela 1fnR\n",
      "Output: select * from fU3l\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela EakxSAl\n",
      "Output: select * from USUYlx\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela Hlt11CGmim\n",
      "Output: select * from kptQm3Q3xa\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela RpKjOXdT9ln20q\n",
      "Output: select * from krzJtg1Ohfx5Mx\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela cLZ71zvw\n",
      "Output: select * from 4oEHvm3aa\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela YRFGeqn7ESC9Ue6\n",
      "Output: select * from YFgggggggMNFnN\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela 1oOlRWvQxjhM\n",
      "Output: select * from 4Or7Xmz8otA3\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela 7tnWRpC3no\n",
      "Output: select * from YFgggglNB\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela o9C9ui\n",
      "Output: select * from DFji7d\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela o\n",
      "Output: select * from o\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela yuhKGT9\n",
      "Output: select * from kK90xlh\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela BGpGul5x\n",
      "Output: select * from 5hiutzptS\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela KVzhslzK8qxpmi\n",
      "Output: select * from 2rYpVm36ggNhMP\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela kUAqz672DJGIzML\n",
      "Output: select * from gGIQ3GQQS6GMmpt\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela 8HnXpHK2cZniFbG4\n",
      "Output: select * from k7AtQ3GQQPMPRnlc\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela WcMQkOrkQllXEQ\n",
      "Output: select * from 41o7MPQrPMPIQB\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela ccf0Faqi71zomP\n",
      "Output: select * from KyyxlbucYglnyl\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela janBylXhhG09\n",
      "Output: select * from FjrpezY8Yt2M\n",
      "\n",
      "(1, 100, 97)\n",
      "Input: traga tudo da tabela 1Qt3kqMPkFPgdcA\n",
      "Output: select * from k7T0zQlYGlmFTi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(0, 20):\n",
    "    s = ptbr_tokenized[t]\n",
    "    s = np.expand_dims(s, axis=0)\n",
    "    \n",
    "    print(s.shape)\n",
    "    \n",
    "    translated = decode(s)\n",
    "    \n",
    "    print(\"Input:\", ptbr[t])\n",
    "    print(\"Output:\", translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
